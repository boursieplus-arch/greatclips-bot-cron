import os
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime

BASE_URL = "https://coupons-2save.com/greatclips"

TELEGRAM_TOKEN = os.environ["TELEGRAM_TOKEN"]
CHAT_ID = int(os.environ["CHAT_ID"])

def send_telegram(text: str):
    """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…"""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    data = {"chat_id": CHAT_ID, "text": text}
    try:
        r = requests.post(url, data=data, timeout=10)
        print(f"Telegram status: {r.status_code}")
        return r.status_code == 200
    except Exception as e:
        print(f"Telegram error: {e}")
        return False

def fetch_page(url):
    """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ ÛŒÚ© ØµÙØ­Ù‡"""
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers, timeout=20)
    resp.raise_for_status()
    return resp.text

def get_coupon_page_links():
    """Ø§Ø² ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒØŒ Ù„ÛŒÙ†Ú© Ù‡Ù…Ù‡ ØµÙØ­Ø§Øª Ú©ÙˆÙ¾Ù† Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ (Ù…Ø«Ù„ /greatclips/$8-99)"""
    html = fetch_page(BASE_URL)
    soup = BeautifulSoup(html, "lxml")
    
    coupon_links = []
    # Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ù‡ ØµÙØ­Ø§Øª Ú©ÙˆÙ¾Ù† Ø§Ø´Ø§Ø±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„ /greatclips/$ Ù‡Ø³ØªÙ†Ø¯)
    for a in soup.find_all("a", href=True):
        href = a["href"]
        # Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù†Ø³Ø¨ÛŒ ÛŒØ§ Ù…Ø·Ù„Ù‚ Ú©Ù‡ Ø¨Ù‡ Ø²ÛŒØ±ØµÙØ­Ø§Øª Ú©ÙˆÙ¾Ù† Ø§Ø´Ø§Ø±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
        if "/greatclips/" in href and href != "/greatclips" and href != "/greatclips/":
            # Ø³Ø§Ø®Øª URL Ú©Ø§Ù…Ù„
            if href.startswith("http"):
                full_url = href
            elif href.startswith("/"):
                full_url = "https://coupons-2save.com" + href
            else:
                full_url = "https://coupons-2save.com/greatclips/" + href
            
            if full_url not in coupon_links and full_url != BASE_URL:
                coupon_links.append(full_url)
    
    return coupon_links

def extract_offer_links(page_url):
    """Ø§Ø² ÛŒÚ© ØµÙØ­Ù‡ Ú©ÙˆÙ¾Ù†ØŒ Ù‡Ù…Ù‡ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ offers.greatclips.com Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
    try:
        html = fetch_page(page_url)
        soup = BeautifulSoup(html, "lxml")
        
        offer_links = set()
        for a in soup.find_all("a", href=True):
            href = a["href"]
            if "offers.greatclips.com" in href:
                offer_links.add(href)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø§Ø² Ù…ØªÙ† ØµÙØ­Ù‡ (Ø¨Ø±Ø§ÛŒ ØªÛŒØªØ±)
        title_tag = soup.find("h1") or soup.find("title")
        title = title_tag.get_text(strip=True) if title_tag else ""
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‚ÛŒÙ…Øª Ø¯Ø± ØªÛŒØªØ± ÛŒØ§ Ù…ØªÙ†
        price_match = re.search(r"\$(\d+\.\d{2})", title)
        price = price_match.group(0) if price_match else "Ù‚ÛŒÙ…Øª Ù†Ø§Ù…Ø´Ø®Øµ"
        
        return {
            "page_url": page_url,
            "title": title[:80],  # Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ 80 Ú©Ø§Ø±Ø§Ú©ØªØ±
            "price": price,
            "offer_links": sorted(offer_links)
        }
    except Exception as e:
        print(f"Error extracting from {page_url}: {e}")
        return None

def main():
    print(f"ðŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±Ù¾ Ú©ÙˆÙ¾Ù†â€ŒÙ‡Ø§ÛŒ Great Clips - {datetime.now()}")
    
    # Û±. Ú¯Ø±ÙØªÙ† Ù„ÛŒÙ†Ú© ØµÙØ­Ø§Øª Ú©ÙˆÙ¾Ù† Ø§Ø² ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ
    print("ðŸ“„ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ØµÙØ­Ø§Øª Ú©ÙˆÙ¾Ù†...")
    coupon_pages = get_coupon_page_links()
    print(f"âœ… {len(coupon_pages)} ØµÙØ­Ù‡ Ú©ÙˆÙ¾Ù† Ù¾ÛŒØ¯Ø§ Ø´Ø¯")
    
    # Û². Ø§Ø² Ù‡Ø± ØµÙØ­Ù‡ØŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ offers Ø±Ø§ Ø¨Ú¯ÛŒØ±
    all_data = []
    for idx, page_url in enumerate(coupon_pages[:10], 1):  # Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ Û±Û° ØµÙØ­Ù‡ Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª
        print(f"ðŸ” [{idx}/{min(10, len(coupon_pages))}] Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´: {page_url}")
        data = extract_offer_links(page_url)
        if data and data["offer_links"]:
            all_data.append(data)
    
    print(f"âœ… Ø¬Ù…Ø¹Ø§Ù‹ {len(all_data)} Ú©ÙˆÙ¾Ù† Ø¨Ø§ Ù„ÛŒÙ†Ú© offer Ù¾ÛŒØ¯Ø§ Ø´Ø¯")
    
    # Û³. Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¯Ø± Ú†Ù†Ø¯ Ø¨Ø®Ø´
    if not all_data:
        message = "âŒ Ù‡ÛŒÚ† Ú©ÙˆÙ¾Ù† Ø¬Ø¯ÛŒØ¯ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."
        send_telegram(message)
        return

    header = f"ðŸŽ‰ Ú©ÙˆÙ¾Ù†â€ŒÙ‡Ø§ÛŒ Great Clips ({datetime.now().strftime('%Y-%m-%d %H:%M')})\n"
    header += f"{'='*40}\n\n"

    message = header
    CHUNK_LIMIT = 3500  # Ú©Ù…ÛŒ Ú©Ù…ØªØ± Ø§Ø² 4096 Ø¨Ø±Ø§ÛŒ Ø­Ø§Ø´ÛŒÙ‡ Ø§Ù…Ù†

    def send_if_meaningful(text: str):
        text = text.rstrip()
        # Ø§Ú¯Ø± Ø®Ø§Ù„ÛŒ ÛŒØ§ ÙÙ‚Ø· Â«Ø§Ø¯Ø§Ù…Ù‡...Â» Ø§Ø³ØªØŒ Ù†ÙØ±Ø³Øª
        if not text:
            return
        if text.strip() == "(Ø§Ø¯Ø§Ù…Ù‡...)":
            return
        send_telegram(text)

    for idx, item in enumerate(all_data, 1):
        block = ""
        block += f"ðŸ”¸ Ú©ÙˆÙ¾Ù† {idx}: {item['price']}\n"
        block += f"ðŸ“„ {item['title']}\n"
        block += f"ðŸ”— ØµÙØ­Ù‡: {item['page_url']}\n"
        block += f"ðŸ’³ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Offer:\n"
        for link in item['offer_links'][:5]:  # Ø­Ø¯Ø§Ú©Ø«Ø± Ûµ Ù„ÛŒÙ†Ú© Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©ÙˆÙ¾Ù†
            block += f"   â€¢ {link}\n"
        block += "\n"

        # Ø§Ú¯Ø± Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ† Ø¨Ù„Ø§Ú© Ø¨Ø§Ø¹Ø« Ø´ÙˆØ¯ Ù¾ÛŒØ§Ù… Ø§Ø² Ø­Ø¯ Ø¨Ú¯Ø°Ø±Ø¯ØŒ Ù¾ÛŒØ§Ù… ÙØ¹Ù„ÛŒ Ø±Ø§ Ø¨ÙØ±Ø³Øª
        if len(message) + len(block) > CHUNK_LIMIT:
            send_if_meaningful(message)
            message = "(Ø§Ø¯Ø§Ù…Ù‡...)\n\n" + block
        else:
            message += block
    
    # Ø§Ø±Ø³Ø§Ù„ Ø¨Ø®Ø´ Ø¢Ø®Ø±
    send_if_meaningful(message)
    
    print("âœ… Ø§ØªÙ…Ø§Ù… Ú©Ø§Ø±")

if __name__ == "__main__":
    main()
